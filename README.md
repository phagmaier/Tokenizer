# ğŸš€ Tokenizer: A Fast C Tokenizer

[![Build](https://img.shields.io/github/actions/workflow/status/phagmaier/Tokenizer/build.yml?branch=main)](https://github.com/phagmaier/Tokenizer/actions)
[![License](https://img.shields.io/github/license/phagmaier/Tokenizer)](./LICENSE)
[![GitHub stars](https://img.shields.io/github/stars/phagmaier/Tokenizer?style=social)](https://github.com/phagmaier/Tokenizer/stargazers)
[![Last Commit](https://img.shields.io/github/last-commit/phagmaier/Tokenizer)](https://github.com/phagmaier/Tokenizer/commits/main)
[![Lines of Code](https://img.shields.io/tokei/lines/github/phagmaier/Tokenizer)](https://github.com/phagmaier/Tokenizer)

A high-performance tokenizer written in C, built for **blazing-fast** text processing. It uses **multithreading** and a **custom memory pool** to tokenize large files with minimal overhead. Tokenization is performed using the **Byte Pair Encoding (BPE)** algorithm.

---

## âœ¨ Key Features

- ğŸ”€ **Multithreaded processing** â€” Efficient tokenization using multiple threads  
- ğŸ§  **Custom memory pool** â€” Fast memory management  
- ğŸ§© **Byte Pair Encoding (BPE)** â€” Subword tokenization strategy  
- ğŸ§® **Configurable vocabulary size**  
- ğŸ“¦ **Adjustable chunk size per thread**

---

## ğŸ› ï¸ Technologies Used

- **C** â€” Core implementation  
- **CMake** â€” Project build system  
- **POSIX Threads (pthreads)** â€” Concurrency support

---

## ğŸ“‹ Prerequisites

- ğŸ§° C Compiler (GCC/Clang) â€” Supporting **C23 standard**
- ğŸ§± CMake â‰¥ 3.16  
- ğŸ› ï¸ Make â€” Typically included in most Unix-like systems

---

## âš™ï¸ Installation

```bash
# Clone the repo
git clone https://github.com/phagmaier/Tokenizer.git

# Enter project directory
cd Tokenizer

# Create and enter build directory
mkdir build && cd build

# Configure project
cmake ..

# Build it
cmake --build .
```

âœ… The `runme` executable will be available in the `build` directory.  
For a release build:  

```bash
cmake --build . --config Release
```

---

## ğŸš¦ Usage & Flags

The tokenizer supports the following CLI flags:

| Flag | Description | Default |
|------|-------------|---------|
| `-i` | Input file path | `../data/data.txt` |
| `-o` | Output file path | `../data/myTokens.txt` |
| `-v` | Vocabulary size | `10000` |
| `-b` | Bytes per thread | `250000` |
| `-t` | Max number of threads | `8` |

**Output format**:  

```
<token_id>, <token_string>\n
```

---

## ğŸ§ª Usage Examples

With custom flags:

```bash
./runme -i ../data/infiniteJest.txt -v 10000 -b 500000 -o ../data/myTokens.txt -t 8
```

Default run:

```bash
./runme
```

âš ï¸ **Note:** File paths should be relative to the `build` directory or be absolute paths.

---

## ğŸ—‚ï¸ Project Structure

```
runme/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ Dics.c / .h         # Dictionary implementation
â”‚   â”œâ”€â”€ Helper.c / .h       # Utility functions
â”‚   â”œâ”€â”€ Token.c / .h        # Token logic
â”‚   â””â”€â”€ Tokenizer.c / .h    # Core tokenizer
â”œâ”€â”€ CMakeLists.txt          # Build config
â””â”€â”€ data/                   # Input/output files
```

---

## âš¡ Performance Benchmarks

- **Large file (167MB)** â€” ~15 seconds using **15 threads**, chunk size ~50k bytes  
- **Infinite Jest (3.2MB)** â€” ~11 seconds with **8 threads**, default settings  

â„¹ï¸ For **better accuracy**, use a larger chunk size per thread. For **max performance**, reduce chunk size.

---

## ğŸ§  Known Limitations

1. âŒ Only supports ASCII
2. âœ‚ï¸ New chunks may start mid-word â€” need better segmentation

---

## ğŸ¤ Contributing

Currently, this project does not have explicit contribution guidelines. PRs are still welcome!

---

## ğŸ“« Contact

**Parker Hagmaier**  
ğŸ“§ [parkerhagmaier@gmail.com](mailto:parkerhagmaier@gmail.com)

---
